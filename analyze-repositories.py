#!/usr/bin/env python3
"""
GitHubä»“åº“æ•´åˆåˆ†æå·¥å…·
æŸ¥è¯¢æ‰€æœ‰ä»“åº“ï¼ŒæŒ‰æ–°äººå‹å¥½çš„æ–¹å¼åˆ†ç±»æ•´åˆ
"""

import os
import json
import csv
import datetime as dt
from collections import defaultdict, Counter
from pathlib import Path
import re

# å¦‚æœæœ‰GitHub tokenï¼Œä½¿ç”¨PyGithub
try:
    from github import Github
    HAS_GITHUB = True
except ImportError:
    HAS_GITHUB = False
    print("è­¦å‘Š: æœªå®‰è£…PyGithubï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

class RepositoryAnalyzer:
    def __init__(self):
        self.repos_data = []
        self.categories = defaultdict(list)
        self.stats = {}
        
    def fetch_repositories(self):
        """è·å–æ‰€æœ‰ä»“åº“ä¿¡æ¯"""
        token = os.getenv("GH_TOKEN") or os.getenv("GITHUB_TOKEN") or os.getenv("GH_TOKEN_VALUE")
        
        if not token or not HAS_GITHUB:
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
            self._create_mock_data()
            return
            
        try:
            gh = Github(token)
            user = gh.get_user()
            print(f"æ­£åœ¨åˆ†æç”¨æˆ· {user.login} çš„æ‰€æœ‰ä»“åº“...")
            
            repos = user.get_repos(visibility="all", sort="updated", direction="desc")
            
            for repo in repos:
                repo_info = {
                    'name': repo.name,
                    'full_name': repo.full_name,
                    'description': repo.description or "",
                    'language': repo.language or "Unknown",
                    'private': repo.private,
                    'archived': repo.archived,
                    'fork': repo.fork,
                    'disabled': repo.disabled,
                    'size': repo.size,
                    'stargazers_count': repo.stargazers_count,
                    'forks_count': repo.forks_count,
                    'open_issues_count': repo.open_issues_count,
                    'default_branch': repo.default_branch,
                    'created_at': repo.created_at.isoformat() if repo.created_at else None,
                    'updated_at': repo.updated_at.isoformat() if repo.updated_at else None,
                    'pushed_at': repo.pushed_at.isoformat() if repo.pushed_at else None,
                    'topics': list(repo.get_topics()) if hasattr(repo, 'get_topics') else [],
                    'has_issues': repo.has_issues,
                    'has_projects': repo.has_projects,
                    'has_wiki': repo.has_wiki,
                    'has_pages': repo.has_pages,
                    'license': repo.license.name if repo.license else None,
                    'clone_url': repo.clone_url,
                    'ssh_url': repo.ssh_url,
                    'html_url': repo.html_url
                }
                
                # è®¡ç®—ä»“åº“æ´»è·ƒåº¦
                if repo.pushed_at:
                    days_since_push = (dt.datetime.utcnow() - repo.pushed_at.replace(tzinfo=None)).days
                    repo_info['stale_days'] = days_since_push
                    repo_info['activity_level'] = self._get_activity_level(days_since_push)
                else:
                    repo_info['stale_days'] = 999999
                    repo_info['activity_level'] = 'inactive'
                
                self.repos_data.append(repo_info)
                
            print(f"æˆåŠŸè·å– {len(self.repos_data)} ä¸ªä»“åº“ä¿¡æ¯")
            
        except Exception as e:
            print(f"è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
            self._create_mock_data()
    
    def _create_mock_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º"""
        mock_repos = [
            {'name': 'my-website', 'language': 'HTML', 'description': 'ä¸ªäººç½‘ç«™', 'size': 1200, 'stale_days': 30, 'private': False, 'archived': False, 'fork': False},
            {'name': 'python-scripts', 'language': 'Python', 'description': 'å¸¸ç”¨Pythonè„šæœ¬', 'size': 800, 'stale_days': 15, 'private': True, 'archived': False, 'fork': False},
            {'name': 'test-repo', 'language': 'JavaScript', 'description': 'æµ‹è¯•ä»“åº“', 'size': 100, 'stale_days': 200, 'private': True, 'archived': False, 'fork': False},
            {'name': 'forked-project', 'language': 'Go', 'description': 'Forkçš„å¼€æºé¡¹ç›®', 'size': 5000, 'stale_days': 100, 'private': False, 'archived': False, 'fork': True},
            {'name': 'old-project', 'language': 'Java', 'description': 'æ—§é¡¹ç›®', 'size': 2000, 'stale_days': 400, 'private': True, 'archived': True, 'fork': False},
            {'name': 'ai-experiments', 'language': 'Python', 'description': 'AIå®éªŒä»£ç ', 'size': 1500, 'stale_days': 45, 'private': True, 'archived': False, 'fork': False},
            {'name': 'config-files', 'language': 'Shell', 'description': 'é…ç½®æ–‡ä»¶é›†åˆ', 'size': 300, 'stale_days': 60, 'private': True, 'archived': False, 'fork': False},
            {'name': 'empty-repo', 'language': None, 'description': '', 'size': 0, 'stale_days': 300, 'private': True, 'archived': False, 'fork': False},
        ]
        
        for repo in mock_repos:
            repo.update({
                'full_name': f'user/{repo["name"]}',
                'language': repo.get('language') or 'Unknown',
                'stargazers_count': 0,
                'forks_count': 0,
                'open_issues_count': 0,
                'default_branch': 'main',
                'topics': [],
                'activity_level': self._get_activity_level(repo['stale_days']),
                'clone_url': f'https://github.com/user/{repo["name"]}.git',
                'html_url': f'https://github.com/user/{repo["name"]}'
            })
        
        self.repos_data = mock_repos
        print(f"ä½¿ç”¨ {len(self.repos_data)} ä¸ªæ¨¡æ‹Ÿä»“åº“è¿›è¡Œæ¼”ç¤º")
    
    def _get_activity_level(self, days):
        """æ ¹æ®å¤©æ•°åˆ¤æ–­æ´»è·ƒåº¦"""
        if days <= 30:
            return 'active'
        elif days <= 90:
            return 'recent'
        elif days <= 180:
            return 'moderate'
        else:
            return 'inactive'
    
    def categorize_repositories(self):
        """æŒ‰æ–°äººå‹å¥½çš„æ–¹å¼åˆ†ç±»ä»“åº“"""
        print("\næ­£åœ¨åˆ†æå’Œåˆ†ç±»ä»“åº“...")
        
        for repo in self.repos_data:
            # 1. æŒ‰çŠ¶æ€åˆ†ç±»ï¼ˆæœ€é‡è¦ï¼‰
            if repo.get('archived'):
                self.categories['ğŸ—„ï¸ å·²å½’æ¡£'].append(repo)
            elif repo.get('fork'):
                self.categories['ğŸ´ Forké¡¹ç›®'].append(repo)
            elif repo.get('size', 0) == 0:
                self.categories['ğŸ“­ ç©ºä»“åº“'].append(repo)
            elif repo.get('stale_days', 0) > 365:
                self.categories['â° é•¿æœŸæœªæ›´æ–°'].append(repo)
            else:
                # 2. æŒ‰ç”¨é€”å’ŒæŠ€æœ¯æ ˆåˆ†ç±»ï¼ˆæ´»è·ƒä»“åº“ï¼‰
                self._categorize_by_purpose_and_tech(repo)
    
    def _categorize_by_purpose_and_tech(self, repo):
        """æŒ‰ç”¨é€”å’ŒæŠ€æœ¯æ ˆåˆ†ç±»æ´»è·ƒä»“åº“"""
        name = repo['name'].lower()
        desc = repo.get('description', '').lower()
        language = repo.get('language', '').lower()
        
        # ç½‘ç«™å’Œå‰ç«¯é¡¹ç›®
        if any(keyword in name + desc for keyword in ['website', 'site', 'blog', 'portfolio', 'landing']):
            self.categories['ğŸŒ ç½‘ç«™é¡¹ç›®'].append(repo)
        elif language in ['html', 'css', 'javascript', 'typescript', 'vue', 'react', 'angular']:
            self.categories['ğŸ¨ å‰ç«¯å¼€å‘'].append(repo)
        
        # åç«¯å’ŒAPI
        elif any(keyword in name + desc for keyword in ['api', 'server', 'backend', 'service']):
            self.categories['âš™ï¸ åç«¯æœåŠ¡'].append(repo)
        elif language in ['python', 'java', 'go', 'rust', 'php', 'ruby', 'c#', 'kotlin']:
            self.categories['ğŸ’» åç«¯å¼€å‘'].append(repo)
        
        # æ•°æ®å’ŒAI
        elif any(keyword in name + desc for keyword in ['data', 'ml', 'ai', 'machine', 'learning', 'analysis', 'jupyter']):
            self.categories['ğŸ¤– AIä¸æ•°æ®'].append(repo)
        
        # å·¥å…·å’Œè„šæœ¬
        elif any(keyword in name + desc for keyword in ['script', 'tool', 'util', 'helper', 'automation']):
            self.categories['ğŸ”§ å·¥å…·è„šæœ¬'].append(repo)
        elif language in ['shell', 'bash', 'powershell']:
            self.categories['ğŸ”§ å·¥å…·è„šæœ¬'].append(repo)
        
        # é…ç½®å’Œæ–‡æ¡£
        elif any(keyword in name + desc for keyword in ['config', 'dotfiles', 'settings', 'setup']):
            self.categories['âš™ï¸ é…ç½®æ–‡ä»¶'].append(repo)
        elif any(keyword in name + desc for keyword in ['doc', 'readme', 'guide', 'tutorial', 'notes']):
            self.categories['ğŸ“š æ–‡æ¡£ç¬”è®°'].append(repo)
        
        # å­¦ä¹ å’Œå®éªŒ
        elif any(keyword in name + desc for keyword in ['learn', 'study', 'practice', 'tutorial', 'example', 'demo']):
            self.categories['ğŸ“ å­¦ä¹ å®éªŒ'].append(repo)
        elif any(keyword in name + desc for keyword in ['test', 'experiment', 'playground', 'sandbox']):
            self.categories['ğŸ§ª æµ‹è¯•å®éªŒ'].append(repo)
        
        # ç§»åŠ¨åº”ç”¨
        elif language in ['swift', 'kotlin', 'dart', 'objective-c']:
            self.categories['ğŸ“± ç§»åŠ¨åº”ç”¨'].append(repo)
        
        # é»˜è®¤åˆ†ç±»
        else:
            self.categories['ğŸ“¦ å…¶ä»–é¡¹ç›®'].append(repo)
    
    def generate_statistics(self):
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        total_repos = len(self.repos_data)
        
        # åŸºç¡€ç»Ÿè®¡
        self.stats = {
            'total_repositories': total_repos,
            'private_repos': sum(1 for r in self.repos_data if r.get('private')),
            'public_repos': sum(1 for r in self.repos_data if not r.get('private')),
            'archived_repos': sum(1 for r in self.repos_data if r.get('archived')),
            'fork_repos': sum(1 for r in self.repos_data if r.get('fork')),
            'empty_repos': sum(1 for r in self.repos_data if r.get('size', 0) == 0),
            'stale_repos': sum(1 for r in self.repos_data if r.get('stale_days', 0) > 180),
        }
        
        # è¯­è¨€ç»Ÿè®¡
        languages = Counter(r.get('language', 'Unknown') for r in self.repos_data if r.get('language'))
        self.stats['top_languages'] = dict(languages.most_common(10))
        
        # æ´»è·ƒåº¦ç»Ÿè®¡
        activity_levels = Counter(r.get('activity_level', 'unknown') for r in self.repos_data)
        self.stats['activity_distribution'] = dict(activity_levels)
        
        # åˆ†ç±»ç»Ÿè®¡
        self.stats['category_distribution'] = {cat: len(repos) for cat, repos in self.categories.items()}
    
    def create_integration_plan(self):
        """åˆ›å»ºæ•´åˆè®¡åˆ’"""
        print("\nç”Ÿæˆæ•´åˆè®¡åˆ’...")
        
        plan = {
            'timestamp': dt.datetime.utcnow().isoformat(),
            'total_repositories': len(self.repos_data),
            'integration_strategy': {},
            'recommended_actions': []
        }
        
        for category, repos in self.categories.items():
            if not repos:
                continue
                
            strategy = self._get_integration_strategy(category, repos)
            plan['integration_strategy'][category] = strategy
        
        # ç”Ÿæˆæ¨èæ“ä½œ
        plan['recommended_actions'] = self._generate_recommendations()
        
        return plan
    
    def _get_integration_strategy(self, category, repos):
        """ä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆæ•´åˆç­–ç•¥"""
        repo_count = len(repos)
        
        if 'å·²å½’æ¡£' in category or 'ç©ºä»“åº“' in category:
            return {
                'action': 'cleanup',
                'description': 'å»ºè®®åˆ é™¤æˆ–ä¿æŒå½’æ¡£çŠ¶æ€',
                'repos_count': repo_count,
                'priority': 'low'
            }
        elif 'Fork' in category:
            return {
                'action': 'review',
                'description': 'æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰ä¿®æ”¹ï¼Œå†³å®šä¿ç•™æˆ–åˆ é™¤',
                'repos_count': repo_count,
                'priority': 'medium'
            }
        elif 'é•¿æœŸæœªæ›´æ–°' in category:
            return {
                'action': 'archive_or_cleanup',
                'description': 'è¯„ä¼°ä»·å€¼åå½’æ¡£æˆ–åˆ é™¤',
                'repos_count': repo_count,
                'priority': 'medium'
            }
        else:
            return {
                'action': 'integrate',
                'description': f'æ•´åˆåˆ°ç»Ÿä¸€ä»“åº“çš„ {category.split()[1] if len(category.split()) > 1 else category} ç›®å½•',
                'repos_count': repo_count,
                'priority': 'high'
            }
    
    def _generate_recommendations(self):
        """ç”Ÿæˆæ•´åˆå»ºè®®"""
        recommendations = []
        
        # æ¸…ç†å»ºè®®
        cleanup_count = len(self.categories.get('ğŸ“­ ç©ºä»“åº“', [])) + len(self.categories.get('ğŸ—„ï¸ å·²å½’æ¡£', []))
        if cleanup_count > 0:
            recommendations.append(f"æ¸…ç† {cleanup_count} ä¸ªç©ºä»“åº“å’Œå·²å½’æ¡£ä»“åº“ï¼Œé‡Šæ”¾è´¦æˆ·ç©ºé—´")
        
        # Forkä»“åº“å»ºè®®
        fork_count = len(self.categories.get('ğŸ´ Forké¡¹ç›®', []))
        if fork_count > 0:
            recommendations.append(f"å®¡æŸ¥ {fork_count} ä¸ªForkä»“åº“ï¼Œä¿ç•™æœ‰ä»·å€¼çš„ä¿®æ”¹")
        
        # æ•´åˆå»ºè®®
        active_categories = [cat for cat, repos in self.categories.items() 
                           if repos and not any(keyword in cat for keyword in ['å·²å½’æ¡£', 'ç©ºä»“åº“', 'Fork', 'é•¿æœŸæœªæ›´æ–°'])]
        
        if active_categories:
            recommendations.append(f"å°† {len(active_categories)} ä¸ªæ´»è·ƒåˆ†ç±»æ•´åˆåˆ°ç»Ÿä¸€ä»“åº“")
            recommendations.append("æŒ‰æŠ€æœ¯æ ˆå’Œç”¨é€”åˆ›å»ºæ¸…æ™°çš„ç›®å½•ç»“æ„")
            recommendations.append("ä¿ç•™é¡¹ç›®å†å²è®°å½•å’Œé‡è¦æ–‡æ¡£")
        
        return recommendations
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        timestamp = dt.datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        with open(f'repository_analysis_{timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump({
                'repositories': self.repos_data,
                'categories': {k: v for k, v in self.categories.items()},
                'statistics': self.stats,
                'analysis_date': dt.datetime.utcnow().isoformat()
            }, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜CSVæŠ¥å‘Š
        with open(f'repository_summary_{timestamp}.csv', 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['name', 'language', 'description', 'category', 'size', 'stale_days', 
                         'activity_level', 'private', 'archived', 'fork', 'action_needed']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for category, repos in self.categories.items():
                for repo in repos:
                    writer.writerow({
                        'name': repo['name'],
                        'language': repo.get('language', 'Unknown'),
                        'description': repo.get('description', ''),
                        'category': category,
                        'size': repo.get('size', 0),
                        'stale_days': repo.get('stale_days', 0),
                        'activity_level': repo.get('activity_level', 'unknown'),
                        'private': repo.get('private', False),
                        'archived': repo.get('archived', False),
                        'fork': repo.get('fork', False),
                        'action_needed': self._get_action_for_repo(category)
                    })
        
        print(f"\nåˆ†æç»“æœå·²ä¿å­˜:")
        print(f"- repository_analysis_{timestamp}.json")
        print(f"- repository_summary_{timestamp}.csv")
        
        return timestamp
    
    def _get_action_for_repo(self, category):
        """æ ¹æ®åˆ†ç±»ç¡®å®šä»“åº“éœ€è¦çš„æ“ä½œ"""
        if 'å·²å½’æ¡£' in category or 'ç©ºä»“åº“' in category:
            return 'DELETE'
        elif 'Fork' in category:
            return 'REVIEW'
        elif 'é•¿æœŸæœªæ›´æ–°' in category:
            return 'ARCHIVE'
        else:
            return 'INTEGRATE'
    
    def print_analysis_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š ä»“åº“åˆ†ææ‘˜è¦")
        print("="*60)
        
        print(f"\nğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
        print(f"  æ€»ä»“åº“æ•°: {self.stats['total_repositories']}")
        print(f"  ç§æœ‰ä»“åº“: {self.stats['private_repos']}")
        print(f"  å…¬å¼€ä»“åº“: {self.stats['public_repos']}")
        print(f"  å·²å½’æ¡£: {self.stats['archived_repos']}")
        print(f"  Forkä»“åº“: {self.stats['fork_repos']}")
        print(f"  ç©ºä»“åº“: {self.stats['empty_repos']}")
        print(f"  é•¿æœŸæœªæ›´æ–°: {self.stats['stale_repos']}")
        
        print(f"\nğŸ·ï¸ åˆ†ç±»ç»“æœ:")
        for category, repos in sorted(self.categories.items()):
            if repos:
                print(f"  {category}: {len(repos)} ä¸ª")
        
        print(f"\nğŸ’» ä¸»è¦ç¼–ç¨‹è¯­è¨€:")
        for lang, count in list(self.stats['top_languages'].items())[:5]:
            print(f"  {lang}: {count} ä¸ª")
        
        print(f"\nğŸ“Š æ´»è·ƒåº¦åˆ†å¸ƒ:")
        for level, count in self.stats['activity_distribution'].items():
            level_name = {'active': 'æ´»è·ƒ', 'recent': 'æœ€è¿‘', 'moderate': 'ä¸€èˆ¬', 'inactive': 'ä¸æ´»è·ƒ'}.get(level, level)
            print(f"  {level_name}: {count} ä¸ª")

def main():
    analyzer = RepositoryAnalyzer()
    
    print("ğŸ” å¼€å§‹åˆ†æGitHubä»“åº“...")
    analyzer.fetch_repositories()
    
    print("\nğŸ“‚ å¼€å§‹åˆ†ç±»æ•´ç†...")
    analyzer.categorize_repositories()
    
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯...")
    analyzer.generate_statistics()
    
    analyzer.print_analysis_summary()
    
    print("\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
    timestamp = analyzer.save_analysis_results()
    
    print("\nğŸ“‹ ç”Ÿæˆæ•´åˆè®¡åˆ’...")
    integration_plan = analyzer.create_integration_plan()
    
    with open(f'integration_plan_{timestamp}.json', 'w', encoding='utf-8') as f:
        json.dump(integration_plan, f, indent=2, ensure_ascii=False)
    
    print(f"æ•´åˆè®¡åˆ’å·²ä¿å­˜: integration_plan_{timestamp}.json")
    
    print("\nâœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœã€‚")

if __name__ == '__main__':
    main()